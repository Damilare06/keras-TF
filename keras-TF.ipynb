{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    # younger person who experienced - 5%\n",
    "    random_younger = randint(13, 64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    #older person who didnt 5%\n",
    "    random_older = randint(65, 100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)    \n",
    "    \n",
    "for i in range(1000):\n",
    "    # younger person who didnt 95%\n",
    "    random_younger = randint(13, 64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    #older person that did experience (95%)\n",
    "    random_older = randint(65, 100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels, train_samples = shuffle(train_labels, train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_sample = scaler.fit_transform(train_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note the model expects numpy array\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#sequential model is a linear stack of layers\n",
    "model = Sequential([\n",
    "    Dense(units = 16, input_shape=(1,), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "210/210 - 0s - loss: 0.6538 - accuracy: 0.5786\n",
      "Epoch 2/30\n",
      "210/210 - 0s - loss: 0.6211 - accuracy: 0.6529\n",
      "Epoch 3/30\n",
      "210/210 - 0s - loss: 0.5877 - accuracy: 0.7114\n",
      "Epoch 4/30\n",
      "210/210 - 0s - loss: 0.5561 - accuracy: 0.7595\n",
      "Epoch 5/30\n",
      "210/210 - 0s - loss: 0.5241 - accuracy: 0.7871\n",
      "Epoch 6/30\n",
      "210/210 - 0s - loss: 0.4919 - accuracy: 0.8233\n",
      "Epoch 7/30\n",
      "210/210 - 0s - loss: 0.4604 - accuracy: 0.8452\n",
      "Epoch 8/30\n",
      "210/210 - 0s - loss: 0.4301 - accuracy: 0.8605\n",
      "Epoch 9/30\n",
      "210/210 - 0s - loss: 0.4025 - accuracy: 0.8733\n",
      "Epoch 10/30\n",
      "210/210 - 0s - loss: 0.3775 - accuracy: 0.8824\n",
      "Epoch 11/30\n",
      "210/210 - 0s - loss: 0.3553 - accuracy: 0.9038\n",
      "Epoch 12/30\n",
      "210/210 - 0s - loss: 0.3359 - accuracy: 0.9033\n",
      "Epoch 13/30\n",
      "210/210 - 0s - loss: 0.3211 - accuracy: 0.9133\n",
      "Epoch 14/30\n",
      "210/210 - 0s - loss: 0.3087 - accuracy: 0.9186\n",
      "Epoch 15/30\n",
      "210/210 - 0s - loss: 0.2990 - accuracy: 0.9181\n",
      "Epoch 16/30\n",
      "210/210 - 0s - loss: 0.2910 - accuracy: 0.9286\n",
      "Epoch 17/30\n",
      "210/210 - 0s - loss: 0.2847 - accuracy: 0.9224\n",
      "Epoch 18/30\n",
      "210/210 - 0s - loss: 0.2797 - accuracy: 0.9314\n",
      "Epoch 19/30\n",
      "210/210 - 0s - loss: 0.2756 - accuracy: 0.9295\n",
      "Epoch 20/30\n",
      "210/210 - 0s - loss: 0.2720 - accuracy: 0.9300\n",
      "Epoch 21/30\n",
      "210/210 - 0s - loss: 0.2689 - accuracy: 0.9357\n",
      "Epoch 22/30\n",
      "210/210 - 0s - loss: 0.2665 - accuracy: 0.9343\n",
      "Epoch 23/30\n",
      "210/210 - 0s - loss: 0.2643 - accuracy: 0.9357\n",
      "Epoch 24/30\n",
      "210/210 - 0s - loss: 0.2626 - accuracy: 0.9319\n",
      "Epoch 25/30\n",
      "210/210 - 0s - loss: 0.2610 - accuracy: 0.9400\n",
      "Epoch 26/30\n",
      "210/210 - 0s - loss: 0.2596 - accuracy: 0.9414\n",
      "Epoch 27/30\n",
      "210/210 - 0s - loss: 0.2584 - accuracy: 0.9390\n",
      "Epoch 28/30\n",
      "210/210 - 0s - loss: 0.2572 - accuracy: 0.9414\n",
      "Epoch 29/30\n",
      "210/210 - 0s - loss: 0.2560 - accuracy: 0.9410\n",
      "Epoch 30/30\n",
      "210/210 - 0s - loss: 0.2552 - accuracy: 0.9400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe3201e8910>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_train_sample, y=train_labels, epochs=30, batch_size=10, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
